{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import wandb\n",
    "import numpy         as np\n",
    "\n",
    "import mlx\n",
    "import mlx.core       as mx\n",
    "import mlx.nn         as nn\n",
    "import mlx.optimizers as optim\n",
    "import mlx.data       as dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    mx.random.seed(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = '../quick-draw-challenge/train_images.npy'\n",
    "train_labels = '../quick-draw-challenge/train_labels.npy'\n",
    "\n",
    "val_images = '../quick-draw-challenge/val_images.npy'\n",
    "val_labels = '../quick-draw-challenge/val_labels.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_labels(images_path: str, labels_path: str):\n",
    "    train_images = np.load(images_path)\n",
    "    train_labels = np.load(labels_path)\n",
    "\n",
    "    images_labels = []\n",
    "    for image, label in zip(train_images, train_labels):\n",
    "        images_labels.append(dict(image=image, label=label))\n",
    "\n",
    "    return images_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    dx.buffer_from_vector(load_images_and_labels(images_path=train_images, \n",
    "                                                 labels_path=train_labels))\n",
    "        .shuffle()\n",
    "        .to_stream()\n",
    "        .key_transform(\"image\", lambda x: x.reshape(28, 28)) # transform flatten array of size 729 to 2-dim array of size 28x28\n",
    "        .key_transform(\"image\", lambda x: np.expand_dims(x, axis=-1)) # Transform HxW image to HxWxC image with one color channel\n",
    "        .image_resize(\"image\", w=224, h=224)\n",
    "        .key_transform(\"image\", lambda x: x.astype(\"float32\"))\n",
    "        .batch(256)\n",
    "        .prefetch(4, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = (\n",
    "    dx.buffer_from_vector(load_images_and_labels(images_path=val_images,\n",
    "                                                 labels_path=val_labels))\n",
    "        .to_stream()\n",
    "        .key_transform(\"image\", lambda x: x.reshape(28, 28))\n",
    "        .key_transform(\"image\", lambda x: np.expand_dims(x, axis=-1))  \n",
    "        .image_resize(\"image\", w=224, h=224) \n",
    "        .key_transform(\"image\", lambda x: x.astype(\"float32\"))\n",
    "        .batch(256)\n",
    "        .prefetch(4, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18 Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/mikheevshow/mlx-convolutional-classifier/refs/heads/master/resources/resnet18_arc.png\" alt=\"resnet18-arch\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBuildingBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, decrease_dim: bool=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(3, 3), padding=1)\n",
    "\n",
    "        self.decrease_dim = decrease_dim\n",
    "        if decrease_dim:\n",
    "            self.conv2         = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=(3, 3), stride=2, padding=1)\n",
    "            self.decrease_conv = nn.Conv2d(in_channels=in_channels,  out_channels=out_channels, kernel_size=(1, 1), stride=2, padding=0)\n",
    "        else: \n",
    "            self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=(3, 3), padding=1) \n",
    "\n",
    "    def __call__(self, x: mx.array) -> mx.array:\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = nn.relu(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.decrease_dim:\n",
    "            x = self.decrease_conv(x)\n",
    "            \n",
    "        out = out + x\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self,in_channels:int, num_classes: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=(7, 7), stride=2, padding=1)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=(2, 2), stride=2, padding=1)\n",
    "\n",
    "        self.base_blocks = [\n",
    "            ResNetBuildingBlock(in_channels=64, out_channels=64),\n",
    "            ResNetBuildingBlock(in_channels=64, out_channels=64),\n",
    "            ResNetBuildingBlock(in_channels=64, out_channels=128, decrease_dim=True),\n",
    "            ResNetBuildingBlock(in_channels=128, out_channels=128),\n",
    "            ResNetBuildingBlock(in_channels=128, out_channels=256, decrease_dim=True),\n",
    "            ResNetBuildingBlock(in_channels=256, out_channels=256),\n",
    "            ResNetBuildingBlock(in_channels=256, out_channels=512, decrease_dim=True),\n",
    "            ResNetBuildingBlock(in_channels=512, out_channels=512)\n",
    "        ]\n",
    "\n",
    "        self.average_pooling = nn.AvgPool2d(kernel_size=(7, 7))\n",
    "        self.classifier      = nn.Linear(input_dims=512, output_dims=num_classes)\n",
    "\n",
    "    def __call__(self, x: mx.array):\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.max_pool(out)\n",
    "        out = nn.relu(out)\n",
    "\n",
    "        for block in self.base_blocks[:-1]:\n",
    "            out = block(out)\n",
    "            out = nn.relu(out)\n",
    "            \n",
    "        out = self.base_blocks[-1](out)    \n",
    "        out = self.average_pooling(out)\n",
    "        \n",
    "        out = out.flatten(start_axis=1)\n",
    "        logits = self.classifier(out)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W&B Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great tutorial from W&B [here](https://wandb.ai/byyoung3/ML_NEWS3/reports/Getting-started-with-Apple-MLX--Vmlldzo5Njk5MTk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_wandb = False\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.init(project=\"MLX_QUICK_AND_DRAW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize model, optimizer and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = mx.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18(in_channels=1, num_classes=345)\n",
    "mx.eval(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "optimizer = optim.SGD(learning_rate=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "def loss_fn(model, X: mx.array, y: mx.array):\n",
    "    return nn.losses.cross_entropy(model(X), y, reduction=\"mean\")\n",
    "\n",
    "loss_and_grad_fn = nn.value_and_grad(model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epoches):\n",
    "    for batch in train_dataset:\n",
    "\n",
    "        X = mx.array(batch['image'])\n",
    "        y = mx.array(batch['label'])\n",
    "\n",
    "        loss, grads = loss_and_grad_fn(model, X, y)\n",
    "\n",
    "        optimizer.update(model, grads)\n",
    "        mx.eval(model.parameters(), optimizer.state)\n",
    "        \n",
    "        print(loss)\n",
    "        \n",
    "    for batch in validation_dataset:\n",
    "\n",
    "        X = mx.array(batch['image'])\n",
    "        y = mx.array(batch['label'])\n",
    "\n",
    "    break    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
