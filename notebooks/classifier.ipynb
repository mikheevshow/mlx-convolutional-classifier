{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import wandb\n",
    "import numpy         as np\n",
    "\n",
    "import mlx\n",
    "import mlx.core       as mx\n",
    "import mlx.nn         as nn\n",
    "import mlx.optimizers as optim\n",
    "import mlx.data       as dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    mx.random.seed(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = '../quick-draw-challenge/train_images.npy'\n",
    "train_labels = '../quick-draw-challenge/train_labels.npy'\n",
    "\n",
    "val_images = '../quick-draw-challenge/val_images.npy'\n",
    "val_labels = '../quick-draw-challenge/val_labels.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_labels(images_path: str, labels_path: str):\n",
    "    train_images = np.load(images_path)\n",
    "    train_labels = np.load(labels_path)\n",
    "\n",
    "    images_labels = []\n",
    "    for image, label in zip(train_images, train_labels):\n",
    "        images_labels.append(dict(image=image, label=label))\n",
    "\n",
    "    return images_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    dx.buffer_from_vector(load_images_and_labels(images_path=train_images, \n",
    "                                                 labels_path=train_labels))\n",
    "        .shuffle()\n",
    "        .to_stream()\n",
    "        .key_transform(\"image\", lambda x: x.reshape(28, 28)) # transform flatten array of size 729 to 2-dim array of size 28x28\n",
    "        .key_transform(\"image\", lambda x: np.expand_dims(x, axis=-1)) # Transform HxW image to HxWxC image with one color channel\n",
    "        .image_resize(\"image\", w=224, h=224)\n",
    "        .key_transform(\"image\", lambda x: x.astype(\"float32\"))\n",
    "        .batch(256)\n",
    "        .prefetch(4, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = (\n",
    "    dx.buffer_from_vector(load_images_and_labels(images_path=val_images,\n",
    "                                                 labels_path=val_labels))\n",
    "        .to_stream()\n",
    "        .key_transform(\"image\", lambda x: x.reshape(28, 28))\n",
    "        .key_transform(\"image\", lambda x: np.expand_dims(x, axis=-1))  \n",
    "        .image_resize(\"image\", w=224, h=224) \n",
    "        .key_transform(\"image\", lambda x: x.astype(\"float32\"))\n",
    "        .batch(256)\n",
    "        .prefetch(4, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18 Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/mikheevshow/mlx-convolutional-classifier/refs/heads/master/resources/resnet18_arc.png\" alt=\"resnet18-arch\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBuildingBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, decrease_dim: bool=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(3, 3), padding=1)\n",
    "\n",
    "        self.decrease_dim = decrease_dim\n",
    "        if decrease_dim:\n",
    "            self.conv2         = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=(3, 3), stride=2, padding=1)\n",
    "            self.decrease_conv = nn.Conv2d(in_channels=in_channels,  out_channels=out_channels, kernel_size=(1, 1), stride=2, padding=0)\n",
    "        else: \n",
    "            self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=(3, 3), padding=1) \n",
    "\n",
    "    def __call__(self, x: mx.array) -> mx.array:\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = nn.relu(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.decrease_dim:\n",
    "            x = self.decrease_conv(x)\n",
    "            \n",
    "        out = out + x\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self,in_channels:int, num_classes: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=(7, 7), stride=2, padding=1)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=(2, 2), stride=2, padding=1)\n",
    "\n",
    "        self.base_blocks = [\n",
    "            ResNetBuildingBlock(in_channels=64, out_channels=64),\n",
    "            ResNetBuildingBlock(in_channels=64, out_channels=64),\n",
    "            ResNetBuildingBlock(in_channels=64, out_channels=128, decrease_dim=True),\n",
    "            ResNetBuildingBlock(in_channels=128, out_channels=128),\n",
    "            ResNetBuildingBlock(in_channels=128, out_channels=256, decrease_dim=True),\n",
    "            ResNetBuildingBlock(in_channels=256, out_channels=256),\n",
    "            ResNetBuildingBlock(in_channels=256, out_channels=512, decrease_dim=True),\n",
    "            ResNetBuildingBlock(in_channels=512, out_channels=512)\n",
    "        ]\n",
    "\n",
    "        self.average_pooling = nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.classifier      = nn.Linear(input_dims=1179648, output_dims=num_classes)\n",
    "\n",
    "    def __call__(self, x: mx.array):\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.max_pool(out)\n",
    "        out = nn.relu(out)\n",
    "\n",
    "        for block in self.base_blocks[:-1]:\n",
    "            out = block(out)\n",
    "            out = nn.relu(out)\n",
    "            \n",
    "        out = self.base_blocks[-1](out)    \n",
    "\n",
    "        print(out.shape)\n",
    "\n",
    "        out = self.average_pooling(out)\n",
    "        out = mx.flatten(out)\n",
    "\n",
    "        print(out.shape)\n",
    "        \n",
    "        logits = self.classifier(out)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W&B Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great tutorial from W&B [here](https://wandb.ai/byyoung3/ML_NEWS3/reports/Getting-started-with-Apple-MLX--Vmlldzo5Njk5MTk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_wandb = False\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.init(project=\"MLX_QUICK_AND_DRAW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize model, optimizer and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = mx.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18(in_channels=1, num_classes=345)\n",
    "mx.eval(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "optimizer = optim.SGD(learning_rate=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "def loss_fn(model, X: mx.array, y: mx.array):\n",
    "    return nn.losses.cross_entropy(model(X), y, reduction=\"mean\")\n",
    "\n",
    "loss_and_grad_fn = nn.value_and_grad(model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 224, 224, 1)\n",
      "(256, 7, 7, 512)\n",
      "(1179648,)\n",
      "array([-0.42911, 0.288466, 0.77963, ..., 2.19505, -2.78398, 1.33222], dtype=float32)\n",
      "(256, 7, 7, 512)\n",
      "(1179648,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Targets shape (256,) does not match logits shape (345,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[186], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(model(X))\n\u001b[0;32m---> 10\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[43mloss_and_grad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# optimizer.update(model, grads)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# mx.eval(model.parameters(), optimizer.state)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print(model.parameters())\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/mlx/nn/utils.py:35\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.wrapped_value_grad_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_value_grad_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 35\u001b[0m     value, grad \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_grad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value, grad\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/mlx/nn/utils.py:29\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.inner_fn\u001b[0;34m(params, *args, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_fn\u001b[39m(params, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     28\u001b[0m     model\u001b[38;5;241m.\u001b[39mupdate(params)\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[184], line 5\u001b[0m, in \u001b[0;36mloss_fn\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_fn\u001b[39m(model, X: mx\u001b[38;5;241m.\u001b[39marray, y: mx\u001b[38;5;241m.\u001b[39marray):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/mlx/nn/losses.py:81\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(logits, targets, weights, axis, label_smoothing, reduction)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Check shapes in two cases: targets as class indices and targets as probabilities\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (targets_as_probs \u001b[38;5;129;01mand\u001b[39;00m targets\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m logits\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m targets_as_probs \u001b[38;5;129;01mand\u001b[39;00m targets\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m _drop_dim(logits\u001b[38;5;241m.\u001b[39mshape, axis)\n\u001b[1;32m     80\u001b[0m ):\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTargets shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtargets\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match logits shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogits\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m     )\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m targets_as_probs:\n\u001b[1;32m     86\u001b[0m     score \u001b[38;5;241m=\u001b[39m mx\u001b[38;5;241m.\u001b[39msum(logits \u001b[38;5;241m*\u001b[39m targets, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "\u001b[0;31mValueError\u001b[0m: Targets shape (256,) does not match logits shape (345,)."
     ]
    }
   ],
   "source": [
    "for epoch in range(epoches):\n",
    "    for batch in train_dataset:\n",
    "\n",
    "        X = mx.array(batch['image'])\n",
    "        y = mx.array(batch['label'])\n",
    "\n",
    "        print(X.shape)\n",
    "        print(model(X))\n",
    "\n",
    "        loss, grads = loss_and_grad_fn(model, X, y)\n",
    "        # optimizer.update(model, grads)\n",
    "\n",
    "        # mx.eval(model.parameters(), optimizer.state)\n",
    "\n",
    "        # print(model.parameters())\n",
    "\n",
    "        break\n",
    "        \n",
    "    for batch in validation_dataset:\n",
    "        break\n",
    "        X = batch   \n",
    "\n",
    "    break    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
